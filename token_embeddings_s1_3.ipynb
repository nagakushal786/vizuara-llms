{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f9b666",
   "metadata": {},
   "source": [
    "## Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab202148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "input_ids=tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Number of tokens present\n",
    "vocab_size=6\n",
    "# Number of dimensions for each vector of a token\n",
    "output_dim=3\n",
    "\n",
    "# Generate random numbers in PyTorch\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# A simple lookup table that stores the embeddings of a fixed dictionary and size\n",
    "embedding_layer=torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1afb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1aaba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_layer(tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b083930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the vector embeddings for particular token IDs\n",
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd86cd",
   "metadata": {},
   "source": [
    "### Positional Embeddings - Encoding Word Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80276ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=50257\n",
    "output_dim=256\n",
    "\n",
    "token_embedding_layer=torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import tensor\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "  def __init__(self, txt, tokenizer, max_length, stride):\n",
    "    self.input_ids=[]\n",
    "    self.target_ids=[]\n",
    "\n",
    "    # Tokenize the entire text\n",
    "    token_ids=tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "    # Apply the sliding window approach to chunk the dataset\n",
    "    for i in range(0, len(token_ids)-max_length, stride):\n",
    "      input_chunk=token_ids[i:i+max_length]\n",
    "      target_chunk=token_ids[i+1:i+max_length+1]\n",
    "      self.input_ids.append(tensor(input_chunk))\n",
    "      self.target_ids.append(tensor(target_chunk))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de26cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def create_data_loader_v1(txt, batch_size=4, max_length=256,\n",
    "                          stride=128, shuffle=True, drop_last=True,\n",
    "                          num_workers=0):\n",
    "  # Initialize the tokenizer\n",
    "  tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "  # Create dataset\n",
    "  dataset=GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "  # Create dataloader\n",
    "  dataloader=DataLoader(dataset, batch_size=batch_size,\n",
    "                        shuffle=shuffle, drop_last=drop_last,\n",
    "                        num_workers=num_workers)\n",
    "  \n",
    "  return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f66e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"verdict.txt\", 'r', encoding='utf-8-sig') as f:\n",
    "  raw_text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=4\n",
    "\n",
    "dataloader=create_data_loader_v1(\n",
    "  raw_text, batch_size=8, max_length=max_length,\n",
    "  stride=max_length, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter=iter(dataloader)\n",
    "# Data batch contains 8 text samples with 4 tokens each\n",
    "inputs, targets=next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f74a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each token, a 256 dimension vector is generated\n",
    "print(f\"Inputs: {inputs}\")\n",
    "print(f\"Input size: {inputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings=token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea16f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length=max_length\n",
    "\n",
    "pos_embedding_layer=torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291b0244",
   "metadata": {},
   "source": [
    "- We need to add one position vector to each of these 4 token embeddings.\n",
    "\n",
    "- The same position embeddings are applied to each input of 4 tokens because there are only 4 positions.\n",
    "\n",
    "- So we have to generate 4 positional embedding vectors from the positional embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embeddings=pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d3ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broad-casting operation\n",
    "input_embeddings=token_embeddings+pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc388770",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0d8d9c",
   "metadata": {},
   "source": [
    "### Recap of Data Pre-Processing Pipeline - Stage 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ea2e8c",
   "metadata": {},
   "source": [
    "The 4 steps involved are:\n",
    "\n",
    "1. `Tokenization` - Converting input text to individual tokens and then to respective token IDs.\n",
    "   - Word based tokenization\n",
    "   - Subword based tokenization (BPE tokenizer)\n",
    "   - Character based tokenization\n",
    "\n",
    "2. `Token Embeddings` - Converting token IDs to vectors.\n",
    "\n",
    "3. `Position Embeddings` - Encoding information about position.\n",
    "\n",
    "4. `Input Embeddings` - Given as input for LLM training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
